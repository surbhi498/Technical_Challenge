{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTzsnALFqilld6rPpSRiXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surbhi498/Technical_Challenge/blob/main/Technical_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLsGgbKxPupg",
        "outputId": "4247340c-43d9-41fb-9e57-c91742a671de"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libportaudio2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igZjGzK8PzS7",
        "outputId": "77b95b8b-18ce-493e-edb8-a03610fe7b27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 14.2 kB/129\r                                                                               \rGet:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 70.6 kB/129\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 70.6 kB/129 kB 55%] [Waiting for headers]\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Fetched 388 kB in 1s (312 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCWZJbf6Ofcf",
        "outputId": "217235bd-e089-499f-8928-763c416c3ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix: (2700, 120)\n",
            "CV Accuracy: 0.9678\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.978     0.970     0.974       270\n",
            "           1      0.977     0.959     0.968       270\n",
            "           2      0.967     0.963     0.965       270\n",
            "           3      0.928     0.956     0.942       270\n",
            "           4      0.993     0.989     0.991       270\n",
            "           5      0.989     0.989     0.989       270\n",
            "           6      0.947     0.919     0.932       270\n",
            "           7      0.981     0.974     0.978       270\n",
            "           8      0.949     0.970     0.960       270\n",
            "           9      0.971     0.989     0.980       270\n",
            "\n",
            "    accuracy                          0.968      2700\n",
            "   macro avg      0.968     0.968     0.968      2700\n",
            "weighted avg      0.968     0.968     0.968      2700\n",
            "\n",
            "Confusion matrix:\n",
            " [[262   1   1   3   0   0   1   1   0   1]\n",
            " [  0 259   1   0   0   3   0   0   1   6]\n",
            " [  1   1 260   6   1   0   1   0   0   0]\n",
            " [  1   0   5 258   0   0   1   2   3   0]\n",
            " [  1   0   0   0 267   0   0   1   1   0]\n",
            " [  0   2   0   0   0 267   0   0   0   1]\n",
            " [  1   0   1   9   1   0 248   1   9   0]\n",
            " [  2   0   0   2   0   0   3 263   0   0]\n",
            " [  0   0   1   0   0   0   7   0 262   0]\n",
            " [  0   2   0   0   0   0   1   0   0 267]]\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import sounddevice as sd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# ---------- FEATURE EXTRACTION ----------\n",
        "def extract_logmel(y, sr, n_mels=40, hop_length=160, win_length=400, fmin=50, fmax=8000):\n",
        "    \"\"\"Extract compact log-mel features + delta for spoken digits.\"\"\"\n",
        "    M = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length,\n",
        "        fmin=fmin, fmax=min(fmax, sr/2), power=2.0\n",
        "    )\n",
        "    logM = librosa.power_to_db(M + 1e-10)\n",
        "    d = librosa.feature.delta(logM)\n",
        "    feat = np.concatenate([logM.mean(axis=1), logM.std(axis=1), d.mean(axis=1)], axis=0)\n",
        "    return feat.astype(np.float32)\n",
        "\n",
        "\n",
        "def decode_wav_bytes(b):\n",
        "    \"\"\"Decode WAV bytes into mono 16k waveform.\"\"\"\n",
        "    y, sr = sf.read(io.BytesIO(b), dtype='float32', always_2d=False)\n",
        "    if y.ndim > 1:\n",
        "        y = np.mean(y, axis=1)  # convert to mono\n",
        "    if sr != 16000:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
        "        sr = 16000\n",
        "    y, _ = librosa.effects.trim(y, top_db=30)  # trim silence\n",
        "    return y, sr\n",
        "\n",
        "\n",
        "def build_feature_matrix(df):\n",
        "    \"\"\"Convert dataframe with audio bytes & labels into feature matrix and label array.\"\"\"\n",
        "    X, y = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        b = row['audio']['bytes']\n",
        "        yi = int(row['label'])\n",
        "        y_wav, sr = decode_wav_bytes(b)\n",
        "        feat = extract_logmel(y_wav, sr)\n",
        "        X.append(feat)\n",
        "        y.append(yi)\n",
        "    return np.vstack(X), np.array(y)\n",
        "\n",
        "\n",
        "# ---------- TRAINING ----------\n",
        "def train_model(df):\n",
        "    X, y = build_feature_matrix(df)\n",
        "    print(\"Feature matrix:\", X.shape)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    Xz = scaler.fit_transform(X)\n",
        "\n",
        "    clf = LogisticRegression(C=1.0, max_iter=1000, n_jobs=-1, random_state=42)\n",
        "\n",
        "    # Cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    y_pred = cross_val_predict(clf, Xz, y, cv=skf, n_jobs=-1)\n",
        "\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    print(f\"CV Accuracy: {acc:.4f}\")\n",
        "    print(\"Classification report:\\n\", classification_report(y, y_pred, digits=3))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y, y_pred))\n",
        "\n",
        "    # Fit final model\n",
        "    clf.fit(Xz, y)\n",
        "    joblib.dump(scaler, \"scaler.joblib\")\n",
        "    joblib.dump(clf, \"digit_lr.joblib\")\n",
        "    np.save(\"X_features.npy\", X)\n",
        "    np.save(\"y_labels.npy\", y)\n",
        "\n",
        "\n",
        "# ---------- PREDICTION ----------\n",
        "def predict_digit(wav_bytes, scaler_path=\"scaler.joblib\", model_path=\"digit_lr.joblib\"):\n",
        "    sc = joblib.load(scaler_path)\n",
        "    model = joblib.load(model_path)\n",
        "    y_wav, sr = decode_wav_bytes(wav_bytes)\n",
        "    feat = extract_logmel(y_wav, sr)[None, :]\n",
        "    feat = sc.transform(feat)\n",
        "    proba = model.predict_proba(feat)[0]\n",
        "    pred = int(np.argmax(proba))\n",
        "    return pred, proba\n",
        "\n",
        "\n",
        "# ---------- USAGE EXAMPLES ----------\n",
        "# 1. TRAIN MODEL:\n",
        "df = pd.read_parquet(\"hf://datasets/mteb/free-spoken-digit-dataset/data/train-00000-of-00001.parquet\")\n",
        "train_model(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test split\n",
        "df_test = pd.read_parquet(\"hf://datasets/mteb/free-spoken-digit-dataset/data/test-00000-of-00001.parquet\")\n",
        "\n",
        "# Build features (same preprocessing as training)\n",
        "X_test, y_test = build_feature_matrix(df_test)\n",
        "\n",
        "# Load trained model + scaler\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "clf = joblib.load(\"digit_lr.joblib\")\n",
        "\n",
        "# Transform features\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6j6X4eaP28q",
        "outputId": "e18641d5-0476-4d80-8ac0-9ccadc9b874e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9733\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        30\n",
            "           1       1.00      0.97      0.98        30\n",
            "           2       1.00      1.00      1.00        30\n",
            "           3       0.96      0.90      0.93        30\n",
            "           4       0.97      1.00      0.98        30\n",
            "           5       1.00      1.00      1.00        30\n",
            "           6       0.90      0.90      0.90        30\n",
            "           7       1.00      1.00      1.00        30\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           0.97       300\n",
            "   macro avg       0.97      0.97      0.97       300\n",
            "weighted avg       0.97      0.97      0.97       300\n",
            "\n",
            "Confusion Matrix:\n",
            " [[30  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 29  0  0  0  0  0  0  0  1]\n",
            " [ 0  0 30  0  0  0  0  0  0  0]\n",
            " [ 1  0  0 27  0  0  2  0  0  0]\n",
            " [ 0  0  0  0 30  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 30  0  0  0  0]\n",
            " [ 0  0  0  1  1  0 27  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 30  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 29  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 30]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import joblib\n",
        "import soundfile as sf\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from IPython.display import Javascript, HTML\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "\n",
        "# MIC RECORDING TEST(BONUS CHALLENGE)\n",
        "\n",
        "def predict_digit(wav_bytes, scaler_path=\"scaler.joblib\", model_path=\"digit_lr.joblib\"):\n",
        "    sc = joblib.load(scaler_path)\n",
        "    model = joblib.load(model_path)\n",
        "    y_wav, sr = sf.read(io.BytesIO(wav_bytes), dtype='float32', always_2d=False)\n",
        "    # Mono\n",
        "    if y_wav.ndim > 1:\n",
        "        y_wav = np.mean(y_wav, axis=1)\n",
        "    # Resample to 16k\n",
        "    if sr != 16000:\n",
        "        import librosa\n",
        "        y_wav = librosa.resample(y_wav, orig_sr=sr, target_sr=16000)\n",
        "        sr = 16000\n",
        "    # Trim silence\n",
        "    import librosa.effects\n",
        "    y_wav, _ = librosa.effects.trim(y_wav, top_db=30)\n",
        "\n",
        "    feat = extract_logmel(y_wav, sr)[None, :]\n",
        "    feat = sc.transform(feat)\n",
        "    proba = model.predict_proba(feat)[0]\n",
        "    pred = int(np.argmax(proba))\n",
        "    return pred, proba\n",
        "\n",
        "def webm_to_wav(webm_bytes):\n",
        "    audio = AudioSegment.from_file(BytesIO(webm_bytes), format=\"webm\")\n",
        "    wav_io = BytesIO()\n",
        "    audio.export(wav_io, format=\"wav\")\n",
        "    return wav_io.getvalue()\n",
        "\n",
        "def record_and_predict_colab(filename='recorded.wav', duration=2):\n",
        "    def save_audio(b64data):\n",
        "        try:\n",
        "            webm_bytes = b64decode(b64data)\n",
        "            if len(webm_bytes) < 1000:\n",
        "                print(\"âŒ Recording too short or empty.\")\n",
        "                return\n",
        "            wav_bytes = webm_to_wav(webm_bytes)\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(wav_bytes)\n",
        "            print(f\"âœ… Saved WAV: {filename} ({len(wav_bytes)} bytes)\")\n",
        "            pred, proba = predict_digit(wav_bytes)\n",
        "            print(f\"ðŸŽ¯ Predicted digit: {pred}\")\n",
        "            print(f\"ðŸ“Š Probabilities: {np.round(proba,3)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Prediction failed: {e}\")\n",
        "\n",
        "    output.register_callback('notebook.save_audio', save_audio)\n",
        "\n",
        "    display(HTML('<button id=\"recordBtn\" style=\"font-size:20px;padding:10px;\">ðŸŽ™ Record</button>'))\n",
        "\n",
        "    js_code = f\"\"\"\n",
        "    const recordButton = document.getElementById(\"recordBtn\");\n",
        "    recordButton.onclick = async () => {{\n",
        "        try {{\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({{ audio: true }});\n",
        "            const mediaRecorder = new MediaRecorder(stream, {{ mimeType: 'audio/webm;codecs=opus' }});\n",
        "            let chunks = [];\n",
        "            mediaRecorder.ondataavailable = e => {{\n",
        "                if (e.data.size > 0) chunks.push(e.data);\n",
        "            }};\n",
        "            mediaRecorder.onstop = async () => {{\n",
        "                if (chunks.length === 0) {{\n",
        "                    console.error(\"No audio chunks recorded.\");\n",
        "                    return;\n",
        "                }}\n",
        "                const blob = new Blob(chunks, {{ type: 'audio/webm;codecs=opus' }});\n",
        "                const reader = new FileReader();\n",
        "                reader.onloadend = () => {{\n",
        "                    const base64data = reader.result.split(',')[1];\n",
        "                    google.colab.kernel.invokeFunction('notebook.save_audio', [base64data], {{}});\n",
        "                }};\n",
        "                reader.readAsDataURL(blob);\n",
        "            }};\n",
        "            mediaRecorder.start();\n",
        "            console.log(\"ðŸŽ™ Recording...\");\n",
        "            setTimeout(() => mediaRecorder.stop(), {duration*1000});\n",
        "        }} catch (err) {{\n",
        "            console.error(\"Mic error:\", err);\n",
        "            alert(\"Microphone access denied or unavailable.\");\n",
        "        }}\n",
        "    }};\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "# Run in Colab\n",
        "record_and_predict_colab(duration=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "3ffL1-hMWfFs",
        "outputId": "b96b7a7b-52eb-4e80-b8ab-767b259b12be"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<button id=\"recordBtn\" style=\"font-size:20px;padding:10px;\">ðŸŽ™ Record</button>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    const recordButton = document.getElementById(\"recordBtn\");\n",
              "    recordButton.onclick = async () => {\n",
              "        try {\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
              "            const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });\n",
              "            let chunks = [];\n",
              "            mediaRecorder.ondataavailable = e => {\n",
              "                if (e.data.size > 0) chunks.push(e.data);\n",
              "            };\n",
              "            mediaRecorder.onstop = async () => {\n",
              "                if (chunks.length === 0) {\n",
              "                    console.error(\"No audio chunks recorded.\");\n",
              "                    return;\n",
              "                }\n",
              "                const blob = new Blob(chunks, { type: 'audio/webm;codecs=opus' });\n",
              "                const reader = new FileReader();\n",
              "                reader.onloadend = () => {\n",
              "                    const base64data = reader.result.split(',')[1];\n",
              "                    google.colab.kernel.invokeFunction('notebook.save_audio', [base64data], {});\n",
              "                };\n",
              "                reader.readAsDataURL(blob);\n",
              "            };\n",
              "            mediaRecorder.start();\n",
              "            console.log(\"ðŸŽ™ Recording...\");\n",
              "            setTimeout(() => mediaRecorder.stop(), 2000);\n",
              "        } catch (err) {\n",
              "            console.error(\"Mic error:\", err);\n",
              "            alert(\"Microphone access denied or unavailable.\");\n",
              "        }\n",
              "    };\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved WAV: recorded.wav (380204 bytes)\n",
            "ðŸŽ¯ Predicted digit: 6\n",
            "ðŸ“Š Probabilities: [0.001 0.038 0.    0.    0.001 0.    0.637 0.323 0.    0.   ]\n",
            "âœ… Saved WAV: recorded.wav (380204 bytes)\n",
            "ðŸŽ¯ Predicted digit: 1\n",
            "ðŸ“Š Probabilities: [0.    0.994 0.    0.    0.    0.    0.002 0.004 0.    0.   ]\n",
            "âœ… Saved WAV: recorded.wav (380204 bytes)\n",
            "ðŸŽ¯ Predicted digit: 1\n",
            "ðŸ“Š Probabilities: [0.    0.963 0.017 0.    0.    0.    0.01  0.009 0.    0.   ]\n"
          ]
        }
      ]
    }
  ]
}